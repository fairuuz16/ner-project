{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8848dc1",
   "metadata": {},
   "source": [
    "# Ekstraksi Informasi dari Berita Kriminal Indonesia menggunakan Named Entity Recognition (NER)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03764f",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c190188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory as SastrawiStopWordRemoverFactory\n",
    "nltk.download('punkt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb429f3",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf77aa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>judul</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>isi_berita</th>\n",
       "      <th>panjang_judul</th>\n",
       "      <th>panjang_isi_berita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.detik.com/sumbagsel/hukum-dan-krim...</td>\n",
       "      <td>4 Anak di Bawah Umur Tersangka Pembunuhan di P...</td>\n",
       "      <td>2024-09-05 20:30:00</td>\n",
       "      <td>Pelaku pembunuhan dan pemerkosaan AA (14) seor...</td>\n",
       "      <td>73</td>\n",
       "      <td>2370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.detik.com/jatim/hukum-dan-kriminal...</td>\n",
       "      <td>26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...</td>\n",
       "      <td>2024-09-05 18:38:00</td>\n",
       "      <td>Dalam waktu kurang lebih 3 bulan, Polres Probo...</td>\n",
       "      <td>64</td>\n",
       "      <td>1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Pekerja Kafe Disiram Air Keras hingga Wajah 'B...</td>\n",
       "      <td>2024-09-04 21:40:00</td>\n",
       "      <td>Seorang pekerja kafe di Cengkareng, MAS (32), ...</td>\n",
       "      <td>71</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Hilang Nyawa Pria di Simalungun gegara Rebutan...</td>\n",
       "      <td>2024-09-03 09:03:00</td>\n",
       "      <td>Hanya gegara rebutan mikrofon untuk bernyanyi ...</td>\n",
       "      <td>70</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...</td>\n",
       "      <td>2024-09-03 08:01:00</td>\n",
       "      <td>Hidup pria bernama Monika Hutauruk (45) harus ...</td>\n",
       "      <td>68</td>\n",
       "      <td>3907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.detik.com/sumbagsel/hukum-dan-krim...   \n",
       "1  https://www.detik.com/jatim/hukum-dan-kriminal...   \n",
       "2  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "3  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "4  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "\n",
       "                                               judul              tanggal  \\\n",
       "0  4 Anak di Bawah Umur Tersangka Pembunuhan di P...  2024-09-05 20:30:00   \n",
       "1  26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...  2024-09-05 18:38:00   \n",
       "2  Pekerja Kafe Disiram Air Keras hingga Wajah 'B...  2024-09-04 21:40:00   \n",
       "3  Hilang Nyawa Pria di Simalungun gegara Rebutan...  2024-09-03 09:03:00   \n",
       "4  Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...  2024-09-03 08:01:00   \n",
       "\n",
       "                                          isi_berita  panjang_judul  \\\n",
       "0  Pelaku pembunuhan dan pemerkosaan AA (14) seor...             73   \n",
       "1  Dalam waktu kurang lebih 3 bulan, Polres Probo...             64   \n",
       "2  Seorang pekerja kafe di Cengkareng, MAS (32), ...             71   \n",
       "3  Hanya gegara rebutan mikrofon untuk bernyanyi ...             70   \n",
       "4  Hidup pria bernama Monika Hutauruk (45) harus ...             68   \n",
       "\n",
       "   panjang_isi_berita  \n",
       "0                2370  \n",
       "1                1764  \n",
       "2                1995  \n",
       "3                1398  \n",
       "4                3907  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/cleaned_all_data.csv\", sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2dfbd",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ddb2ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil setelah membersihkan tanda baca secara terpisah:\n",
      "                                               judul  \\\n",
      "0  4 Anak di Bawah Umur Tersangka Pembunuhan di P...   \n",
      "1  26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...   \n",
      "2  Pekerja Kafe Disiram Air Keras hingga Wajah 'B...   \n",
      "3  Hilang Nyawa Pria di Simalungun gegara Rebutan...   \n",
      "4  Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...   \n",
      "\n",
      "                                            judul_rp  \\\n",
      "0  4 Anak di Bawah Umur Tersangka Pembunuhan di P...   \n",
      "1  26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...   \n",
      "2  Pekerja Kafe Disiram Air Keras hingga Wajah Be...   \n",
      "3  Hilang Nyawa Pria di Simalungun gegara Rebutan...   \n",
      "4  Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...   \n",
      "\n",
      "                                          isi_berita  \\\n",
      "0  Pelaku pembunuhan dan pemerkosaan AA (14) seor...   \n",
      "1  Dalam waktu kurang lebih 3 bulan, Polres Probo...   \n",
      "2  Seorang pekerja kafe di Cengkareng, MAS (32), ...   \n",
      "3  Hanya gegara rebutan mikrofon untuk bernyanyi ...   \n",
      "4  Hidup pria bernama Monika Hutauruk (45) harus ...   \n",
      "\n",
      "                                              isi_rp  \n",
      "0  Pelaku pembunuhan dan pemerkosaan AA 14 seoran...  \n",
      "1  Dalam waktu kurang lebih 3 bulan Polres Probol...  \n",
      "2  Seorang pekerja kafe di Cengkareng MAS 32 didu...  \n",
      "3  Hanya gegara rebutan mikrofon untuk bernyanyi ...  \n",
      "4  Hidup pria bernama Monika Hutauruk 45 harus be...  \n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "df['judul_rp'] = df['judul'].apply(remove_punctuation)\n",
    "\n",
    "df['isi_rp'] = df['isi_berita'].apply(remove_punctuation)\n",
    "\n",
    "print(\"Hasil setelah membersihkan tanda baca secara terpisah:\")\n",
    "print(df[['judul', 'judul_rp', 'isi_berita', 'isi_rp']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0e5f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul_tokens</th>\n",
       "      <th>isi_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, Anak, di, Bawah, Umur, Tersangka, Pembunuh...</td>\n",
       "      <td>[Pelaku, pembunuhan, dan, pemerkosaan, AA, 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[26, Tersangka, Dibekuk, Selama, 3, Bulan, Ter...</td>\n",
       "      <td>[Dalam, waktu, kurang, lebih, 3, bulan, Polres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Pekerja, Kafe, Disiram, Air, Keras, hingga, W...</td>\n",
       "      <td>[Seorang, pekerja, kafe, di, Cengkareng, MAS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hilang, Nyawa, Pria, di, Simalungun, gegara, ...</td>\n",
       "      <td>[Hanya, gegara, rebutan, mikrofon, untuk, bern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Utang, Rp, 3, Juta, Bikin, Pegawai, Akper, Te...</td>\n",
       "      <td>[Hidup, pria, bernama, Monika, Hutauruk, 45, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        judul_tokens  \\\n",
       "0  [4, Anak, di, Bawah, Umur, Tersangka, Pembunuh...   \n",
       "1  [26, Tersangka, Dibekuk, Selama, 3, Bulan, Ter...   \n",
       "2  [Pekerja, Kafe, Disiram, Air, Keras, hingga, W...   \n",
       "3  [Hilang, Nyawa, Pria, di, Simalungun, gegara, ...   \n",
       "4  [Utang, Rp, 3, Juta, Bikin, Pegawai, Akper, Te...   \n",
       "\n",
       "                                          isi_tokens  \n",
       "0  [Pelaku, pembunuhan, dan, pemerkosaan, AA, 14,...  \n",
       "1  [Dalam, waktu, kurang, lebih, 3, bulan, Polres...  \n",
       "2  [Seorang, pekerja, kafe, di, Cengkareng, MAS, ...  \n",
       "3  [Hanya, gegara, rebutan, mikrofon, untuk, bern...  \n",
       "4  [Hidup, pria, bernama, Monika, Hutauruk, 45, h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['judul_rp'] = df['judul_rp'].fillna('')\n",
    "df['isi_rp'] = df['isi_rp'].fillna('')\n",
    "\n",
    "# Tokenisasi \n",
    "df['judul_tokens'] = df['judul_rp'].apply(word_tokenize)\n",
    "df['isi_tokens'] = df['isi_rp'].apply(word_tokenize)\n",
    "\n",
    "# Hasil tokenisasi\n",
    "df[['judul_tokens', 'isi_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3ebec",
   "metadata": {},
   "source": [
    "### Casefolding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54de430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul_tokens_lower</th>\n",
       "      <th>isi_tokens_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, anak, di, bawah, umur, tersangka, pembunuh...</td>\n",
       "      <td>[pelaku, pembunuhan, dan, pemerkosaan, aa, 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[26, tersangka, dibekuk, selama, 3, bulan, ter...</td>\n",
       "      <td>[dalam, waktu, kurang, lebih, 3, bulan, polres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pekerja, kafe, disiram, air, keras, hingga, w...</td>\n",
       "      <td>[seorang, pekerja, kafe, di, cengkareng, mas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hilang, nyawa, pria, di, simalungun, gegara, ...</td>\n",
       "      <td>[hanya, gegara, rebutan, mikrofon, untuk, bern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[utang, rp, 3, juta, bikin, pegawai, akper, te...</td>\n",
       "      <td>[hidup, pria, bernama, monika, hutauruk, 45, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  judul_tokens_lower  \\\n",
       "0  [4, anak, di, bawah, umur, tersangka, pembunuh...   \n",
       "1  [26, tersangka, dibekuk, selama, 3, bulan, ter...   \n",
       "2  [pekerja, kafe, disiram, air, keras, hingga, w...   \n",
       "3  [hilang, nyawa, pria, di, simalungun, gegara, ...   \n",
       "4  [utang, rp, 3, juta, bikin, pegawai, akper, te...   \n",
       "\n",
       "                                    isi_tokens_lower  \n",
       "0  [pelaku, pembunuhan, dan, pemerkosaan, aa, 14,...  \n",
       "1  [dalam, waktu, kurang, lebih, 3, bulan, polres...  \n",
       "2  [seorang, pekerja, kafe, di, cengkareng, mas, ...  \n",
       "3  [hanya, gegara, rebutan, mikrofon, untuk, bern...  \n",
       "4  [hidup, pria, bernama, monika, hutauruk, 45, h...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['judul_tokens_lower'] = df['judul_tokens'].apply(lambda tokens: [token.lower() for token in tokens])\n",
    "df['isi_tokens_lower'] = df['isi_tokens'].apply(lambda tokens: [token.lower() for token in tokens])\n",
    "\n",
    "df[['judul_tokens_lower', 'isi_tokens_lower']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299fbe9",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06b870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul_stemmed</th>\n",
       "      <th>isi_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, anak, di, bawah, umur, sangka, bunuh, di, ...</td>\n",
       "      <td>[laku, bunuh, dan, perkosa, aa, 14, orang, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[26, sangka, bekuk, lama, 3, bulan, akhir, di,...</td>\n",
       "      <td>[dalam, waktu, kurang, lebih, 3, bulan, polres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[kerja, kafe, siram, air, keras, hingga, wajah...</td>\n",
       "      <td>[orang, kerja, kafe, di, cengkareng, mas, 32, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hilang, nyawa, pria, di, simalungun, gegara, ...</td>\n",
       "      <td>[hanya, gegara, rebut, mikrofon, untuk, nyanyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[utang, rp, 3, juta, bikin, pegawai, akper, te...</td>\n",
       "      <td>[hidup, pria, nama, monika, hutauruk, 45, haru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       judul_stemmed  \\\n",
       "0  [4, anak, di, bawah, umur, sangka, bunuh, di, ...   \n",
       "1  [26, sangka, bekuk, lama, 3, bulan, akhir, di,...   \n",
       "2  [kerja, kafe, siram, air, keras, hingga, wajah...   \n",
       "3  [hilang, nyawa, pria, di, simalungun, gegara, ...   \n",
       "4  [utang, rp, 3, juta, bikin, pegawai, akper, te...   \n",
       "\n",
       "                                         isi_stemmed  \n",
       "0  [laku, bunuh, dan, perkosa, aa, 14, orang, rem...  \n",
       "1  [dalam, waktu, kurang, lebih, 3, bulan, polres...  \n",
       "2  [orang, kerja, kafe, di, cengkareng, mas, 32, ...  \n",
       "3  [hanya, gegara, rebut, mikrofon, untuk, nyanyi...  \n",
       "4  [hidup, pria, nama, monika, hutauruk, 45, haru...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "df['judul_stemmed'] = df['judul_tokens_lower'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "df['isi_stemmed'] = df['isi_tokens_lower'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "\n",
    "df[['judul_stemmed', 'isi_stemmed']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575a66d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>judul</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>isi_berita</th>\n",
       "      <th>panjang_judul</th>\n",
       "      <th>panjang_isi_berita</th>\n",
       "      <th>judul_rp</th>\n",
       "      <th>isi_rp</th>\n",
       "      <th>judul_tokens</th>\n",
       "      <th>isi_tokens</th>\n",
       "      <th>judul_tokens_lower</th>\n",
       "      <th>isi_tokens_lower</th>\n",
       "      <th>judul_stemmed</th>\n",
       "      <th>isi_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.detik.com/sumbagsel/hukum-dan-krim...</td>\n",
       "      <td>4 Anak di Bawah Umur Tersangka Pembunuhan di P...</td>\n",
       "      <td>2024-09-05 20:30:00</td>\n",
       "      <td>Pelaku pembunuhan dan pemerkosaan AA (14) seor...</td>\n",
       "      <td>73</td>\n",
       "      <td>2370</td>\n",
       "      <td>4 Anak di Bawah Umur Tersangka Pembunuhan di P...</td>\n",
       "      <td>Pelaku pembunuhan dan pemerkosaan AA 14 seoran...</td>\n",
       "      <td>[4, Anak, di, Bawah, Umur, Tersangka, Pembunuh...</td>\n",
       "      <td>[Pelaku, pembunuhan, dan, pemerkosaan, AA, 14,...</td>\n",
       "      <td>[4, anak, di, bawah, umur, tersangka, pembunuh...</td>\n",
       "      <td>[pelaku, pembunuhan, dan, pemerkosaan, aa, 14,...</td>\n",
       "      <td>[4, anak, di, bawah, umur, sangka, bunuh, di, ...</td>\n",
       "      <td>[laku, bunuh, dan, perkosa, aa, 14, orang, rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.detik.com/jatim/hukum-dan-kriminal...</td>\n",
       "      <td>26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...</td>\n",
       "      <td>2024-09-05 18:38:00</td>\n",
       "      <td>Dalam waktu kurang lebih 3 bulan, Polres Probo...</td>\n",
       "      <td>64</td>\n",
       "      <td>1764</td>\n",
       "      <td>26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...</td>\n",
       "      <td>Dalam waktu kurang lebih 3 bulan Polres Probol...</td>\n",
       "      <td>[26, Tersangka, Dibekuk, Selama, 3, Bulan, Ter...</td>\n",
       "      <td>[Dalam, waktu, kurang, lebih, 3, bulan, Polres...</td>\n",
       "      <td>[26, tersangka, dibekuk, selama, 3, bulan, ter...</td>\n",
       "      <td>[dalam, waktu, kurang, lebih, 3, bulan, polres...</td>\n",
       "      <td>[26, sangka, bekuk, lama, 3, bulan, akhir, di,...</td>\n",
       "      <td>[dalam, waktu, kurang, lebih, 3, bulan, polres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Pekerja Kafe Disiram Air Keras hingga Wajah 'B...</td>\n",
       "      <td>2024-09-04 21:40:00</td>\n",
       "      <td>Seorang pekerja kafe di Cengkareng, MAS (32), ...</td>\n",
       "      <td>71</td>\n",
       "      <td>1995</td>\n",
       "      <td>Pekerja Kafe Disiram Air Keras hingga Wajah Be...</td>\n",
       "      <td>Seorang pekerja kafe di Cengkareng MAS 32 didu...</td>\n",
       "      <td>[Pekerja, Kafe, Disiram, Air, Keras, hingga, W...</td>\n",
       "      <td>[Seorang, pekerja, kafe, di, Cengkareng, MAS, ...</td>\n",
       "      <td>[pekerja, kafe, disiram, air, keras, hingga, w...</td>\n",
       "      <td>[seorang, pekerja, kafe, di, cengkareng, mas, ...</td>\n",
       "      <td>[kerja, kafe, siram, air, keras, hingga, wajah...</td>\n",
       "      <td>[orang, kerja, kafe, di, cengkareng, mas, 32, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Hilang Nyawa Pria di Simalungun gegara Rebutan...</td>\n",
       "      <td>2024-09-03 09:03:00</td>\n",
       "      <td>Hanya gegara rebutan mikrofon untuk bernyanyi ...</td>\n",
       "      <td>70</td>\n",
       "      <td>1398</td>\n",
       "      <td>Hilang Nyawa Pria di Simalungun gegara Rebutan...</td>\n",
       "      <td>Hanya gegara rebutan mikrofon untuk bernyanyi ...</td>\n",
       "      <td>[Hilang, Nyawa, Pria, di, Simalungun, gegara, ...</td>\n",
       "      <td>[Hanya, gegara, rebutan, mikrofon, untuk, bern...</td>\n",
       "      <td>[hilang, nyawa, pria, di, simalungun, gegara, ...</td>\n",
       "      <td>[hanya, gegara, rebutan, mikrofon, untuk, bern...</td>\n",
       "      <td>[hilang, nyawa, pria, di, simalungun, gegara, ...</td>\n",
       "      <td>[hanya, gegara, rebut, mikrofon, untuk, nyanyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...</td>\n",
       "      <td>2024-09-03 08:01:00</td>\n",
       "      <td>Hidup pria bernama Monika Hutauruk (45) harus ...</td>\n",
       "      <td>68</td>\n",
       "      <td>3907</td>\n",
       "      <td>Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...</td>\n",
       "      <td>Hidup pria bernama Monika Hutauruk 45 harus be...</td>\n",
       "      <td>[Utang, Rp, 3, Juta, Bikin, Pegawai, Akper, Te...</td>\n",
       "      <td>[Hidup, pria, bernama, Monika, Hutauruk, 45, h...</td>\n",
       "      <td>[utang, rp, 3, juta, bikin, pegawai, akper, te...</td>\n",
       "      <td>[hidup, pria, bernama, monika, hutauruk, 45, h...</td>\n",
       "      <td>[utang, rp, 3, juta, bikin, pegawai, akper, te...</td>\n",
       "      <td>[hidup, pria, nama, monika, hutauruk, 45, haru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.detik.com/sumbagsel/hukum-dan-krim...   \n",
       "1  https://www.detik.com/jatim/hukum-dan-kriminal...   \n",
       "2  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "3  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "4  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "\n",
       "                                               judul              tanggal  \\\n",
       "0  4 Anak di Bawah Umur Tersangka Pembunuhan di P...  2024-09-05 20:30:00   \n",
       "1  26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...  2024-09-05 18:38:00   \n",
       "2  Pekerja Kafe Disiram Air Keras hingga Wajah 'B...  2024-09-04 21:40:00   \n",
       "3  Hilang Nyawa Pria di Simalungun gegara Rebutan...  2024-09-03 09:03:00   \n",
       "4  Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...  2024-09-03 08:01:00   \n",
       "\n",
       "                                          isi_berita  panjang_judul  \\\n",
       "0  Pelaku pembunuhan dan pemerkosaan AA (14) seor...             73   \n",
       "1  Dalam waktu kurang lebih 3 bulan, Polres Probo...             64   \n",
       "2  Seorang pekerja kafe di Cengkareng, MAS (32), ...             71   \n",
       "3  Hanya gegara rebutan mikrofon untuk bernyanyi ...             70   \n",
       "4  Hidup pria bernama Monika Hutauruk (45) harus ...             68   \n",
       "\n",
       "   panjang_isi_berita                                           judul_rp  \\\n",
       "0                2370  4 Anak di Bawah Umur Tersangka Pembunuhan di P...   \n",
       "1                1764  26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...   \n",
       "2                1995  Pekerja Kafe Disiram Air Keras hingga Wajah Be...   \n",
       "3                1398  Hilang Nyawa Pria di Simalungun gegara Rebutan...   \n",
       "4                3907  Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...   \n",
       "\n",
       "                                              isi_rp  \\\n",
       "0  Pelaku pembunuhan dan pemerkosaan AA 14 seoran...   \n",
       "1  Dalam waktu kurang lebih 3 bulan Polres Probol...   \n",
       "2  Seorang pekerja kafe di Cengkareng MAS 32 didu...   \n",
       "3  Hanya gegara rebutan mikrofon untuk bernyanyi ...   \n",
       "4  Hidup pria bernama Monika Hutauruk 45 harus be...   \n",
       "\n",
       "                                        judul_tokens  \\\n",
       "0  [4, Anak, di, Bawah, Umur, Tersangka, Pembunuh...   \n",
       "1  [26, Tersangka, Dibekuk, Selama, 3, Bulan, Ter...   \n",
       "2  [Pekerja, Kafe, Disiram, Air, Keras, hingga, W...   \n",
       "3  [Hilang, Nyawa, Pria, di, Simalungun, gegara, ...   \n",
       "4  [Utang, Rp, 3, Juta, Bikin, Pegawai, Akper, Te...   \n",
       "\n",
       "                                          isi_tokens  \\\n",
       "0  [Pelaku, pembunuhan, dan, pemerkosaan, AA, 14,...   \n",
       "1  [Dalam, waktu, kurang, lebih, 3, bulan, Polres...   \n",
       "2  [Seorang, pekerja, kafe, di, Cengkareng, MAS, ...   \n",
       "3  [Hanya, gegara, rebutan, mikrofon, untuk, bern...   \n",
       "4  [Hidup, pria, bernama, Monika, Hutauruk, 45, h...   \n",
       "\n",
       "                                  judul_tokens_lower  \\\n",
       "0  [4, anak, di, bawah, umur, tersangka, pembunuh...   \n",
       "1  [26, tersangka, dibekuk, selama, 3, bulan, ter...   \n",
       "2  [pekerja, kafe, disiram, air, keras, hingga, w...   \n",
       "3  [hilang, nyawa, pria, di, simalungun, gegara, ...   \n",
       "4  [utang, rp, 3, juta, bikin, pegawai, akper, te...   \n",
       "\n",
       "                                    isi_tokens_lower  \\\n",
       "0  [pelaku, pembunuhan, dan, pemerkosaan, aa, 14,...   \n",
       "1  [dalam, waktu, kurang, lebih, 3, bulan, polres...   \n",
       "2  [seorang, pekerja, kafe, di, cengkareng, mas, ...   \n",
       "3  [hanya, gegara, rebutan, mikrofon, untuk, bern...   \n",
       "4  [hidup, pria, bernama, monika, hutauruk, 45, h...   \n",
       "\n",
       "                                       judul_stemmed  \\\n",
       "0  [4, anak, di, bawah, umur, sangka, bunuh, di, ...   \n",
       "1  [26, sangka, bekuk, lama, 3, bulan, akhir, di,...   \n",
       "2  [kerja, kafe, siram, air, keras, hingga, wajah...   \n",
       "3  [hilang, nyawa, pria, di, simalungun, gegara, ...   \n",
       "4  [utang, rp, 3, juta, bikin, pegawai, akper, te...   \n",
       "\n",
       "                                         isi_stemmed  \n",
       "0  [laku, bunuh, dan, perkosa, aa, 14, orang, rem...  \n",
       "1  [dalam, waktu, kurang, lebih, 3, bulan, polres...  \n",
       "2  [orang, kerja, kafe, di, cengkareng, mas, 32, ...  \n",
       "3  [hanya, gegara, rebut, mikrofon, untuk, nyanyi...  \n",
       "4  [hidup, pria, nama, monika, hutauruk, 45, haru...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6982e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/stemmed.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e63139",
   "metadata": {},
   "source": [
    "### Stop Word Removal & POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "766732b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>judul</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>isi_berita</th>\n",
       "      <th>panjang_judul</th>\n",
       "      <th>panjang_isi_berita</th>\n",
       "      <th>judul_rp</th>\n",
       "      <th>isi_rp</th>\n",
       "      <th>judul_tokens</th>\n",
       "      <th>isi_tokens</th>\n",
       "      <th>judul_tokens_lower</th>\n",
       "      <th>isi_tokens_lower</th>\n",
       "      <th>judul_stemmed</th>\n",
       "      <th>isi_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.detik.com/sumbagsel/hukum-dan-krim...</td>\n",
       "      <td>4 Anak di Bawah Umur Tersangka Pembunuhan di P...</td>\n",
       "      <td>2024-09-05 20:30:00</td>\n",
       "      <td>Pelaku pembunuhan dan pemerkosaan AA (14) seor...</td>\n",
       "      <td>73</td>\n",
       "      <td>2370</td>\n",
       "      <td>4 Anak di Bawah Umur Tersangka Pembunuhan di P...</td>\n",
       "      <td>Pelaku pembunuhan dan pemerkosaan AA 14 seoran...</td>\n",
       "      <td>['4', 'Anak', 'di', 'Bawah', 'Umur', 'Tersangk...</td>\n",
       "      <td>['Pelaku', 'pembunuhan', 'dan', 'pemerkosaan',...</td>\n",
       "      <td>['4', 'anak', 'di', 'bawah', 'umur', 'tersangk...</td>\n",
       "      <td>['pelaku', 'pembunuhan', 'dan', 'pemerkosaan',...</td>\n",
       "      <td>['4', 'anak', 'di', 'bawah', 'umur', 'sangka',...</td>\n",
       "      <td>['laku', 'bunuh', 'dan', 'perkosa', 'aa', '14'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.detik.com/jatim/hukum-dan-kriminal...</td>\n",
       "      <td>26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...</td>\n",
       "      <td>2024-09-05 18:38:00</td>\n",
       "      <td>Dalam waktu kurang lebih 3 bulan, Polres Probo...</td>\n",
       "      <td>64</td>\n",
       "      <td>1764</td>\n",
       "      <td>26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...</td>\n",
       "      <td>Dalam waktu kurang lebih 3 bulan Polres Probol...</td>\n",
       "      <td>['26', 'Tersangka', 'Dibekuk', 'Selama', '3', ...</td>\n",
       "      <td>['Dalam', 'waktu', 'kurang', 'lebih', '3', 'bu...</td>\n",
       "      <td>['26', 'tersangka', 'dibekuk', 'selama', '3', ...</td>\n",
       "      <td>['dalam', 'waktu', 'kurang', 'lebih', '3', 'bu...</td>\n",
       "      <td>['26', 'sangka', 'bekuk', 'lama', '3', 'bulan'...</td>\n",
       "      <td>['dalam', 'waktu', 'kurang', 'lebih', '3', 'bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Pekerja Kafe Disiram Air Keras hingga Wajah 'B...</td>\n",
       "      <td>2024-09-04 21:40:00</td>\n",
       "      <td>Seorang pekerja kafe di Cengkareng, MAS (32), ...</td>\n",
       "      <td>71</td>\n",
       "      <td>1995</td>\n",
       "      <td>Pekerja Kafe Disiram Air Keras hingga Wajah Be...</td>\n",
       "      <td>Seorang pekerja kafe di Cengkareng MAS 32 didu...</td>\n",
       "      <td>['Pekerja', 'Kafe', 'Disiram', 'Air', 'Keras',...</td>\n",
       "      <td>['Seorang', 'pekerja', 'kafe', 'di', 'Cengkare...</td>\n",
       "      <td>['pekerja', 'kafe', 'disiram', 'air', 'keras',...</td>\n",
       "      <td>['seorang', 'pekerja', 'kafe', 'di', 'cengkare...</td>\n",
       "      <td>['kerja', 'kafe', 'siram', 'air', 'keras', 'hi...</td>\n",
       "      <td>['orang', 'kerja', 'kafe', 'di', 'cengkareng',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Hilang Nyawa Pria di Simalungun gegara Rebutan...</td>\n",
       "      <td>2024-09-03 09:03:00</td>\n",
       "      <td>Hanya gegara rebutan mikrofon untuk bernyanyi ...</td>\n",
       "      <td>70</td>\n",
       "      <td>1398</td>\n",
       "      <td>Hilang Nyawa Pria di Simalungun gegara Rebutan...</td>\n",
       "      <td>Hanya gegara rebutan mikrofon untuk bernyanyi ...</td>\n",
       "      <td>['Hilang', 'Nyawa', 'Pria', 'di', 'Simalungun'...</td>\n",
       "      <td>['Hanya', 'gegara', 'rebutan', 'mikrofon', 'un...</td>\n",
       "      <td>['hilang', 'nyawa', 'pria', 'di', 'simalungun'...</td>\n",
       "      <td>['hanya', 'gegara', 'rebutan', 'mikrofon', 'un...</td>\n",
       "      <td>['hilang', 'nyawa', 'pria', 'di', 'simalungun'...</td>\n",
       "      <td>['hanya', 'gegara', 'rebut', 'mikrofon', 'untu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.detik.com/sumut/hukum-dan-kriminal...</td>\n",
       "      <td>Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...</td>\n",
       "      <td>2024-09-03 08:01:00</td>\n",
       "      <td>Hidup pria bernama Monika Hutauruk (45) harus ...</td>\n",
       "      <td>68</td>\n",
       "      <td>3907</td>\n",
       "      <td>Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...</td>\n",
       "      <td>Hidup pria bernama Monika Hutauruk 45 harus be...</td>\n",
       "      <td>['Utang', 'Rp', '3', 'Juta', 'Bikin', 'Pegawai...</td>\n",
       "      <td>['Hidup', 'pria', 'bernama', 'Monika', 'Hutaur...</td>\n",
       "      <td>['utang', 'rp', '3', 'juta', 'bikin', 'pegawai...</td>\n",
       "      <td>['hidup', 'pria', 'bernama', 'monika', 'hutaur...</td>\n",
       "      <td>['utang', 'rp', '3', 'juta', 'bikin', 'pegawai...</td>\n",
       "      <td>['hidup', 'pria', 'nama', 'monika', 'hutauruk'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.detik.com/sumbagsel/hukum-dan-krim...   \n",
       "1  https://www.detik.com/jatim/hukum-dan-kriminal...   \n",
       "2  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "3  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "4  https://www.detik.com/sumut/hukum-dan-kriminal...   \n",
       "\n",
       "                                               judul              tanggal  \\\n",
       "0  4 Anak di Bawah Umur Tersangka Pembunuhan di P...  2024-09-05 20:30:00   \n",
       "1  26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...  2024-09-05 18:38:00   \n",
       "2  Pekerja Kafe Disiram Air Keras hingga Wajah 'B...  2024-09-04 21:40:00   \n",
       "3  Hilang Nyawa Pria di Simalungun gegara Rebutan...  2024-09-03 09:03:00   \n",
       "4  Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...  2024-09-03 08:01:00   \n",
       "\n",
       "                                          isi_berita  panjang_judul  \\\n",
       "0  Pelaku pembunuhan dan pemerkosaan AA (14) seor...             73   \n",
       "1  Dalam waktu kurang lebih 3 bulan, Polres Probo...             64   \n",
       "2  Seorang pekerja kafe di Cengkareng, MAS (32), ...             71   \n",
       "3  Hanya gegara rebutan mikrofon untuk bernyanyi ...             70   \n",
       "4  Hidup pria bernama Monika Hutauruk (45) harus ...             68   \n",
       "\n",
       "   panjang_isi_berita                                           judul_rp  \\\n",
       "0                2370  4 Anak di Bawah Umur Tersangka Pembunuhan di P...   \n",
       "1                1764  26 Tersangka Dibekuk Selama 3 Bulan Terakhir d...   \n",
       "2                1995  Pekerja Kafe Disiram Air Keras hingga Wajah Be...   \n",
       "3                1398  Hilang Nyawa Pria di Simalungun gegara Rebutan...   \n",
       "4                3907  Utang Rp 3 Juta Bikin Pegawai Akper Tewas di T...   \n",
       "\n",
       "                                              isi_rp  \\\n",
       "0  Pelaku pembunuhan dan pemerkosaan AA 14 seoran...   \n",
       "1  Dalam waktu kurang lebih 3 bulan Polres Probol...   \n",
       "2  Seorang pekerja kafe di Cengkareng MAS 32 didu...   \n",
       "3  Hanya gegara rebutan mikrofon untuk bernyanyi ...   \n",
       "4  Hidup pria bernama Monika Hutauruk 45 harus be...   \n",
       "\n",
       "                                        judul_tokens  \\\n",
       "0  ['4', 'Anak', 'di', 'Bawah', 'Umur', 'Tersangk...   \n",
       "1  ['26', 'Tersangka', 'Dibekuk', 'Selama', '3', ...   \n",
       "2  ['Pekerja', 'Kafe', 'Disiram', 'Air', 'Keras',...   \n",
       "3  ['Hilang', 'Nyawa', 'Pria', 'di', 'Simalungun'...   \n",
       "4  ['Utang', 'Rp', '3', 'Juta', 'Bikin', 'Pegawai...   \n",
       "\n",
       "                                          isi_tokens  \\\n",
       "0  ['Pelaku', 'pembunuhan', 'dan', 'pemerkosaan',...   \n",
       "1  ['Dalam', 'waktu', 'kurang', 'lebih', '3', 'bu...   \n",
       "2  ['Seorang', 'pekerja', 'kafe', 'di', 'Cengkare...   \n",
       "3  ['Hanya', 'gegara', 'rebutan', 'mikrofon', 'un...   \n",
       "4  ['Hidup', 'pria', 'bernama', 'Monika', 'Hutaur...   \n",
       "\n",
       "                                  judul_tokens_lower  \\\n",
       "0  ['4', 'anak', 'di', 'bawah', 'umur', 'tersangk...   \n",
       "1  ['26', 'tersangka', 'dibekuk', 'selama', '3', ...   \n",
       "2  ['pekerja', 'kafe', 'disiram', 'air', 'keras',...   \n",
       "3  ['hilang', 'nyawa', 'pria', 'di', 'simalungun'...   \n",
       "4  ['utang', 'rp', '3', 'juta', 'bikin', 'pegawai...   \n",
       "\n",
       "                                    isi_tokens_lower  \\\n",
       "0  ['pelaku', 'pembunuhan', 'dan', 'pemerkosaan',...   \n",
       "1  ['dalam', 'waktu', 'kurang', 'lebih', '3', 'bu...   \n",
       "2  ['seorang', 'pekerja', 'kafe', 'di', 'cengkare...   \n",
       "3  ['hanya', 'gegara', 'rebutan', 'mikrofon', 'un...   \n",
       "4  ['hidup', 'pria', 'bernama', 'monika', 'hutaur...   \n",
       "\n",
       "                                       judul_stemmed  \\\n",
       "0  ['4', 'anak', 'di', 'bawah', 'umur', 'sangka',...   \n",
       "1  ['26', 'sangka', 'bekuk', 'lama', '3', 'bulan'...   \n",
       "2  ['kerja', 'kafe', 'siram', 'air', 'keras', 'hi...   \n",
       "3  ['hilang', 'nyawa', 'pria', 'di', 'simalungun'...   \n",
       "4  ['utang', 'rp', '3', 'juta', 'bikin', 'pegawai...   \n",
       "\n",
       "                                         isi_stemmed  \n",
       "0  ['laku', 'bunuh', 'dan', 'perkosa', 'aa', '14'...  \n",
       "1  ['dalam', 'waktu', 'kurang', 'lebih', '3', 'bu...  \n",
       "2  ['orang', 'kerja', 'kafe', 'di', 'cengkareng',...  \n",
       "3  ['hanya', 'gegara', 'rebut', 'mikrofon', 'untu...  \n",
       "4  ['hidup', 'pria', 'nama', 'monika', 'hutauruk'...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/stemmed.csv\", sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece3cc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Using cached flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Using cached boto3-1.38.23-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
      "  Using cached conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flair) (0.27.1)\n",
      "Collecting langdetect>=1.0.9 (from flair)\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lxml>=4.8.0 (from flair)\n",
      "  Using cached lxml-5.4.0-cp311-cp311-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flair) (3.8.4)\n",
      "Collecting more-itertools>=8.13.0 (from flair)\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Using cached mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Using cached pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from flair) (2.9.0.post0)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Using cached pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flair) (2024.11.6)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flair) (1.4.1.post1)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Using cached segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Using cached sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flair) (0.9.0)\n",
      "Requirement already satisfied: torch>=1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flair) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flair) (4.66.2)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Using cached transformer_smaller_training_vocab-0.4.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.48.1)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Using cached wikipedia_api-0.8.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bioc<3.0.0,>=2.0.0 (from flair)\n",
      "  Using cached bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Using cached jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Using cached intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.5.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.25.3)\n",
      "Collecting botocore<1.39.0,>=1.38.23 (from boto3>=1.20.27->flair)\n",
      "  Using cached botocore-1.38.23-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.20.27->flair)\n",
      "  Using cached s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from botocore<1.39.0,>=1.38.23->boto3>=1.20.27->flair) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->flair) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deprecated>=1.2.13->flair) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gdown>=4.4.0->flair) (4.13.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (23.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.2.3->flair) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.2.3->flair) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=2.2.3->flair) (3.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mpld3>=0.3->flair) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.2->flair) (3.4.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.1->flair) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.1->flair) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.1->flair) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.63.0->flair) (0.4.6)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from accelerate>=0.26.0->transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (5.9.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.7)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->mpld3>=0.3->flair) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
      "Using cached flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
      "Using cached bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Using cached conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Using cached boto3-1.38.23-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.38.23-py3-none-any.whl (13.6 MB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Using cached jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading lxml-5.4.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/3.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 1.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 1.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 744.7 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 342.4 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 342.4 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 342.4 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.3/3.8 MB 345.8 kB/s eta 0:00:08\n",
      "   ------------- -------------------------- 1.3/3.8 MB 345.8 kB/s eta 0:00:08\n",
      "   ------------- -------------------------- 1.3/3.8 MB 345.8 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 364.7 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 364.7 kB/s eta 0:00:07\n",
      "   ------------------- -------------------- 1.8/3.8 MB 387.1 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 1.8/3.8 MB 387.1 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 1.8/3.8 MB 387.1 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 1.8/3.8 MB 387.1 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/3.8 MB 368.1 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 2.4/3.8 MB 306.4 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 2.4/3.8 MB 306.4 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 2.4/3.8 MB 306.4 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 2.4/3.8 MB 306.4 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 2.4/3.8 MB 306.4 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 2.4/3.8 MB 306.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 2.6/3.8 MB 293.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 2.6/3.8 MB 293.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 2.6/3.8 MB 293.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 2.6/3.8 MB 293.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 2.6/3.8 MB 293.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 2.6/3.8 MB 293.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 2.6/3.8 MB 293.2 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 2.9/3.8 MB 275.9 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 2.9/3.8 MB 275.9 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 2.9/3.8 MB 275.9 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 2.9/3.8 MB 275.9 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 2.9/3.8 MB 275.9 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 2.9/3.8 MB 275.9 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 3.1/3.8 MB 267.4 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 3.1/3.8 MB 267.4 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 3.1/3.8 MB 267.4 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 280.0 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 3.7/3.8 MB 293.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 293.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 294.9 kB/s eta 0:00:00\n",
      "Using cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Using cached mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "Using cached pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Using cached segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/991.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/991.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/991.5 kB ? eta -:--:--\n",
      "   -------------------- ----------------- 524.3/991.5 kB 342.2 kB/s eta 0:00:02\n",
      "   -------------------- ----------------- 524.3/991.5 kB 342.2 kB/s eta 0:00:02\n",
      "   ------------------------------ ------- 786.4/991.5 kB 479.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 991.5/991.5 kB 536.3 kB/s eta 0:00:00\n",
      "Using cached transformer_smaller_training_vocab-0.4.1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993255 sha256=c5374115a6887a357f394604c8953d0a87361a4f25f64d8381060997f83228e3\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "  Building wheel for pptree (setup.py): started\n",
      "  Building wheel for pptree (setup.py): finished with status 'done'\n",
      "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4613 sha256=474ef5f4160857ef9e4936548947d30dc08ad942df2f5277a2241709df2356fb\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\68\\8a\\eb\\d683aa6d09dc68ebfde2f37566ddc8807837c4415b4fd2b04c\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16902 sha256=604813ac23b88cf58ea4f902b276ad1028bbb8a9189acad48d7789a42e02eea9\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\73\\63\\89\\7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15437 sha256=4dbfa006f89ff976510b8ffae1c4022d36a035f2b86aa1bc90ca5194aafec873\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\0b\\0f\\39\\e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13773 sha256=0afe0b005e394179352c536c5eb92677e440fc5a49511248c587e150c380be79\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\1a\\b0\\8c\\4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for intervaltree (setup.py): started\n",
      "  Building wheel for intervaltree (setup.py): finished with status 'done'\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26125 sha256=84cb3df17cbc4839bdda39a25cef29a400355f80624511151a9242f9bad9c1d1\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\31\\d7\\d9\\eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
      "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
      "Installing collected packages: sqlitedict, sentencepiece, pptree, docopt, segtok, more-itertools, lxml, langdetect, jsonlines, jmespath, intervaltree, ftfy, deprecated, conllu, wikipedia-api, botocore, bioc, s3transfer, pytorch-revgrad, mpld3, gdown, boto3, transformer-smaller-training-vocab, flair\n",
      "\n",
      "   - --------------------------------------  1/24 [sentencepiece]\n",
      "   ------ ---------------------------------  4/24 [segtok]\n",
      "   ------ ---------------------------------  4/24 [segtok]\n",
      "   -------- -------------------------------  5/24 [more-itertools]\n",
      "   ---------- -----------------------------  6/24 [lxml]\n",
      "   ---------- -----------------------------  6/24 [lxml]\n",
      "   ---------- -----------------------------  6/24 [lxml]\n",
      "   ----------- ----------------------------  7/24 [langdetect]\n",
      "   --------------- ------------------------  9/24 [jmespath]\n",
      "   ---------------- ----------------------- 10/24 [intervaltree]\n",
      "   ------------------ --------------------- 11/24 [ftfy]\n",
      "   -------------------- ------------------- 12/24 [deprecated]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   ------------------------- -------------- 15/24 [botocore]\n",
      "   -------------------------- ------------- 16/24 [bioc]\n",
      "   -------------------------- ------------- 16/24 [bioc]\n",
      "   -------------------------- ------------- 16/24 [bioc]\n",
      "   ---------------------------- ----------- 17/24 [s3transfer]\n",
      "   ---------------------------- ----------- 17/24 [s3transfer]\n",
      "   ------------------------------ --------- 18/24 [pytorch-revgrad]\n",
      "   ------------------------------- -------- 19/24 [mpld3]\n",
      "   ------------------------------- -------- 19/24 [mpld3]\n",
      "   --------------------------------- ------ 20/24 [gdown]\n",
      "   --------------------------------- ------ 20/24 [gdown]\n",
      "   ----------------------------------- ---- 21/24 [boto3]\n",
      "   ----------------------------------- ---- 21/24 [boto3]\n",
      "   ----------------------------------- ---- 21/24 [boto3]\n",
      "   ----------------------------------- ---- 21/24 [boto3]\n",
      "   ------------------------------ -- 22/24 [transformer-smaller-training-vocab]\n",
      "   ------------------------------ -- 22/24 [transformer-smaller-training-vocab]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   -------------------------------------- - 23/24 [flair]\n",
      "   ---------------------------------------- 24/24 [flair]\n",
      "\n",
      "Successfully installed bioc-2.1 boto3-1.38.23 botocore-1.38.23 conllu-4.5.3 deprecated-1.2.18 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 gdown-5.2.0 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 lxml-5.4.0 more-itertools-10.7.0 mpld3-0.5.10 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.13.0 segtok-1.5.11 sentencepiece-0.2.0 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.1 wikipedia-api-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'pptree' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pptree'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'sqlitedict' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sqlitedict'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'wikipedia-api' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia-api'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  DEPRECATION: Building 'intervaltree' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'intervaltree'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd5589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil memuat stopwords dari Sastrawi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.flair\\models\\upos-multi\\models--flair--upos-multi. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 11:58:21,777 SequenceTagger predicts: Dictionary with 17 tags: NOUN, PUNCT, ADP, VERB, ADJ, DET, PROPN, ADV, PRON, AUX, CCONJ, NUM, SCONJ, PART, X, SYM, INTJ\n",
      "Model Flair POS tagger berhasil dimuat.\n",
      "Error: File 'cleaned_all_data.csv' tidak ditemukan. Pastikan file ada di direktori yang benar.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast # Untuk mengubah string representasi list menjadi list aktual\n",
    "\n",
    "# Pastikan Pustaka Sastrawi telah terinstal jika Anda ingin menggunakannya secara penuh\n",
    "# Jika tidak, placeholder stopwords akan digunakan.\n",
    "try:\n",
    "    from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "    stopword_factory = StopWordRemoverFactory()\n",
    "    stopwords_set = set(stopword_factory.get_stop_words())\n",
    "    print(\"Berhasil memuat stopwords dari Sastrawi.\")\n",
    "except ImportError:\n",
    "    print(\"Pustaka Sastrawi tidak ditemukan. Menggunakan placeholder stopwords.\")\n",
    "    print(\"Anda dapat menginstal Sastrawi dengan: pip install Sastrawi\")\n",
    "    stopwords_set = set(['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'maka', 'sampai', 'saat', 'hal', 'akan', 'lagi', 'telah', 'oleh', 'sebagai', 'dan', 'di', 'dari']) # Contoh stopwords\n",
    "\n",
    "# --- Pengaturan Flair POS Tagger ---\n",
    "# Pastikan Anda telah menginstal flair: pip install flair\n",
    "try:\n",
    "    from flair.data import Sentence\n",
    "    from flair.models import SequenceTagger\n",
    "    tagger = SequenceTagger.load('pos-multi')\n",
    "    print(\"Model Flair POS tagger berhasil dimuat.\")\n",
    "except ImportError:\n",
    "    print(\"Pustaka Flair tidak ditemukan. Silakan install dengan: pip install flair\")\n",
    "    tagger = None\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat model Flair POS tagger: {e}\")\n",
    "    print(\"Pastikan Anda memiliki koneksi internet untuk pengunduhan pertama.\")\n",
    "    tagger = None # Atur tagger ke None jika gagal memuat\n",
    "\n",
    "# --- Fungsi-fungsi Pemrosesan ---\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    \"\"\"Mengubah string representasi list menjadi list, menangani error dan NaN.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Jika bukan string list yang valid, kembalikan list kosong atau tangani sesuai kebutuhan\n",
    "        # Misalnya, jika itu adalah string biasa yang tidak dimaksudkan sebagai list, Anda mungkin ingin men-splitnya.\n",
    "        # Untuk saat ini, kita asumsikan input adalah stringified list atau NaN.\n",
    "        print(f\"Peringatan: Gagal mengurai string sebagai list: {val}. Mengembalikan list kosong.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Menghapus stopwords dari daftar token.\"\"\"\n",
    "    if not isinstance(tokens, list):\n",
    "        # Ini mungkin terjadi jika safe_literal_eval mengembalikan sesuatu selain list\n",
    "        # atau jika kolom asli tidak berisi stringified list.\n",
    "        print(f\"Peringatan: Input untuk remove_stopwords bukan list: {tokens}. Mengembalikan list kosong.\")\n",
    "        return []\n",
    "    return [token for token in tokens if token.lower() not in stopwords_set and token.strip() != '']\n",
    "\n",
    "def pos_tag_tokens_with_flair(tokens):\n",
    "    \"\"\"\n",
    "    Melakukan POS tagging pada daftar token menggunakan Flair.\n",
    "    Input: Daftar string (token).\n",
    "    Output: Daftar tuple (token, pos_tag).\n",
    "    \"\"\"\n",
    "    if not tagger:\n",
    "        print(\"Tagger Flair tidak dimuat. Mengembalikan POS tags kosong.\")\n",
    "        return [(token, 'UNKN') for token in tokens]\n",
    "    \n",
    "    if not tokens or not isinstance(tokens, list) or not all(isinstance(t, str) for t in tokens):\n",
    "        # Jika tokens adalah list kosong setelah stopword removal, itu valid.\n",
    "        if isinstance(tokens, list) and not tokens:\n",
    "            return []\n",
    "        print(f\"Peringatan: Input untuk pos_tag_tokens_with_flair tidak valid: {tokens}. Mengembalikan list kosong.\")\n",
    "        return []\n",
    "\n",
    "    sentence_text = \" \".join(tokens)\n",
    "    sentence = Sentence(sentence_text)\n",
    "\n",
    "    try:\n",
    "        tagger.predict(sentence)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat prediksi Flair: {e}\")\n",
    "        return [(token, 'ERR') for token in tokens]\n",
    "\n",
    "    pos_tags_from_flair = []\n",
    "    for token_obj in sentence.tokens:\n",
    "        pos_tags_from_flair.append((token_obj.text, token_obj.get_tag('pos').value))\n",
    "    \n",
    "    # Penanganan ketidakcocokan tokenisasi antara input dan Flair\n",
    "    if len(pos_tags_from_flair) == len(tokens):\n",
    "        return pos_tags_from_flair\n",
    "    else:\n",
    "        print(f\"Peringatan: Jumlah token tidak cocok setelah Flair. Input: {len(tokens)} token, Flair: {len(pos_tags_from_flair)} token.\")\n",
    "        print(f\"Token input: {tokens}\")\n",
    "        print(f\"Tag Flair: {[(t.text, t.get_tag('pos').value) for t in sentence.tokens]}\")\n",
    "        \n",
    "        # Implementasi penyelarasan (alignment)\n",
    "        realigned_tags = []\n",
    "        flair_token_texts = [pt[0] for pt in pos_tags_from_flair]\n",
    "        \n",
    "        original_idx = 0\n",
    "        flair_idx = 0\n",
    "\n",
    "        while original_idx < len(tokens):\n",
    "            original_token = tokens[original_idx]\n",
    "            current_reconstructed_flair_segment = \"\"\n",
    "            tags_for_current_original_token = []\n",
    "            \n",
    "            temp_flair_idx_start = flair_idx\n",
    "            while flair_idx < len(flair_token_texts):\n",
    "                segment_to_add = flair_token_texts[flair_idx]\n",
    "                \n",
    "                # Normalisasi untuk perbandingan (misalnya, hilangkan spasi jika Flair memecah token secara berbeda)\n",
    "                # Ini adalah logika yang disederhanakan; kasus kompleks mungkin memerlukan penanganan lebih lanjut.\n",
    "                combined_segment = (current_reconstructed_flair_segment + segment_to_add).replace(\" \", \"\")\n",
    "                original_token_compare = original_token.replace(\" \", \"\")\n",
    "\n",
    "                if combined_segment == original_token_compare:\n",
    "                    current_reconstructed_flair_segment += segment_to_add\n",
    "                    tags_for_current_original_token.append(pos_tags_from_flair[flair_idx][1])\n",
    "                    flair_idx += 1\n",
    "                    break \n",
    "                elif original_token_compare.startswith(combined_segment):\n",
    "                    current_reconstructed_flair_segment += segment_to_add\n",
    "                    tags_for_current_original_token.append(pos_tags_from_flair[flair_idx][1])\n",
    "                    flair_idx += 1\n",
    "                else:\n",
    "                    break \n",
    "            \n",
    "            if current_reconstructed_flair_segment.replace(\" \", \"\") == original_token.replace(\" \", \"\") and tags_for_current_original_token:\n",
    "                realigned_tags.append((original_token, tags_for_current_original_token[0])) # Ambil tag pertama\n",
    "            else:\n",
    "                realigned_tags.append((original_token, 'UNKN_ALIGN')) # Tandai jika penyelarasan gagal\n",
    "                flair_idx = temp_flair_idx_start # Reset flair_idx untuk coba lagi dengan token asli berikutnya\n",
    "                # Untuk menghindari infinite loop jika ada ketidakcocokan persisten:\n",
    "                if flair_idx < len(flair_token_texts) and original_idx +1 < len(tokens) :\n",
    "                     # Coba majukan flair_idx jika token berikutnya tidak cocok, ini spekulatif\n",
    "                    if not tokens[original_idx+1].startswith(flair_token_texts[flair_idx]):\n",
    "                         flair_idx +=1\n",
    "                elif flair_idx == len(flair_token_texts) and original_idx +1 < len(tokens):\n",
    "                    # Flair tokens habis, tapi masih ada original tokens\n",
    "                    pass # Akan ditandai UNKN_ALIGN di iterasi berikutnya\n",
    "\n",
    "            original_idx += 1\n",
    "            \n",
    "        if len(realigned_tags) == len(tokens):\n",
    "            return realigned_tags\n",
    "        else: # Fallback jika panjang akhir tidak sama\n",
    "            print(\"Penyelarasan akhir gagal menghasilkan jumlah token yang sama. Mengembalikan token asli dengan tag UNKN.\")\n",
    "            return [(token, 'UNKN_FINAL') for token in tokens]\n",
    "\n",
    "file_path = 'cleaned_all_data.csv' \n",
    "\n",
    "judul_stemmed_input_col = 'judul_stemmed'\n",
    "isi_stemmed_input_col = 'isi_stemmed'\n",
    "\n",
    "original_judul_display_col = 'judul'\n",
    "original_isi_display_col = 'isi_berita' \n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"\\nBerhasil memuat DataFrame dari {file_path}.\")\n",
    "    print(\"Kolom yang tersedia:\", df.columns.tolist())\n",
    "\n",
    "    missing_cols = []\n",
    "    if judul_stemmed_input_col not in df.columns:\n",
    "        missing_cols.append(judul_stemmed_input_col)\n",
    "    if isi_stemmed_input_col not in df.columns:\n",
    "        missing_cols.append(isi_stemmed_input_col)\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Error: Kolom input berikut tidak ditemukan di CSV: {', '.join(missing_cols)}. Harap periksa file CSV dan nama kolom.\")\n",
    "    elif not tagger:\n",
    "        print(\"\\nPOS tagging dengan Flair tidak dapat dilakukan karena tagger gagal dimuat.\")\n",
    "    else:\n",
    "        print(f\"\\nMemproses kolom '{judul_stemmed_input_col}' dan '{isi_stemmed_input_col}'...\")\n",
    "\n",
    "        # 1. Konversi stringified list menjadi list aktual\n",
    "        df['judul_stemmed_list'] = df[judul_stemmed_input_col].apply(safe_literal_eval).copy()\n",
    "        df['isi_stemmed_list'] = df[isi_stemmed_input_col].apply(safe_literal_eval).copy()\n",
    "        print(\"Langkah 1: Konversi kolom stemmed menjadi list selesai.\")\n",
    "\n",
    "        # 2. Penghapusan Stopword\n",
    "        df['judul_stemmed_nostop'] = df['judul_stemmed_list'].apply(remove_stopwords)\n",
    "        df['isi_stemmed_nostop'] = df['isi_stemmed_list'].apply(remove_stopwords)\n",
    "        print(\"Langkah 2: Penghapusan Stopword selesai.\")\n",
    "\n",
    "        # 3. POS Tagging dengan Flair\n",
    "        df['judul_pos_flair'] = df['judul_stemmed_nostop'].apply(pos_tag_tokens_with_flair)\n",
    "        df['isi_pos_flair'] = df['isi_stemmed_nostop'].apply(pos_tag_tokens_with_flair)\n",
    "        print(\"Langkah 3: POS Tagging dengan Flair selesai.\")\n",
    "        \n",
    "        print(\"\\nContoh hasil pemrosesan DataFrame:\")\n",
    "        \n",
    "        display_cols_judul = []\n",
    "        if original_judul_display_col in df.columns:\n",
    "            display_cols_judul.append(original_judul_display_col)\n",
    "        display_cols_judul.extend([judul_stemmed_input_col, 'judul_stemmed_nostop', 'judul_pos_flair'])\n",
    "        \n",
    "        display_cols_isi = []\n",
    "        if original_isi_display_col in df.columns:\n",
    "            display_cols_isi.append(original_isi_display_col)\n",
    "        display_cols_isi.extend([isi_stemmed_input_col, 'isi_stemmed_nostop', 'isi_pos_flair'])\n",
    "\n",
    "        print(\"\\n--- Judul ---\")\n",
    "        print(df[display_cols_judul].head())\n",
    "        print(\"\\n--- Isi ---\")\n",
    "        print(df[display_cols_isi].head())\n",
    "\n",
    "        if not df['isi_pos_flair'].empty and df['isi_pos_flair'].iloc[0] is not None and len(df['isi_pos_flair'].iloc[0]) > 0 :\n",
    "            print(\"\\nContoh detail 'isi_pos_flair' untuk entri pertama:\")\n",
    "            for token, tag in df['isi_pos_flair'].iloc[0]:\n",
    "                print(f\"Token: {token}, POS: {tag}\")\n",
    "        else:\n",
    "            print(f\"\\nTidak ada data 'isi_pos_flair' untuk ditampilkan pada entri pertama atau kolom '{isi_stemmed_input_col}' mungkin kosong setelah diproses.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path}' tidak ditemukan. Pastikan file ada di direktori yang benar dan nama file sudah sesuai.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: File '{file_path}' kosong.\")\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error saat memproses DataFrame: {e}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['judul', 'judul_stemmed_nostop', 'judul_pos_nostop', 'isi_stemmed_nostop', 'isi_pos_nostop']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f72ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/prepocessed_all_data.csv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
